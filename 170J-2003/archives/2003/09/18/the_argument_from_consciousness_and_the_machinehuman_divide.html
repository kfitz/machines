<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1" />

<title>The Literary Machine: The Argument from consciousness and the machine/human divide</title>

<link rel="stylesheet" href="../../../styles-site.css" type="text/css" />

<link rel="alternate" type="application/rss+xml" title="RSS" href="http://machines.pomona.edu/170J-2003/index.rdf" />

<link rel="start" href="http://machines.pomona.edu/170J-2003/" title="Home" />
<link rel="prev" href="http://machines.pomona.edu/170J-2003/archives/2003/09/17/turingwiener.html" title="Turing/Wiener" />

<link rel="next" href="http://machines.pomona.edu/170J-2003/archives/2003/09/22/remedios_varo.html" title="Remedios Varo" />


<script type="text/javascript" language="javascript">
<!--

function OpenTrackback (c) {
    window.open(c,
                    'trackback',
                    'width=480,height=480,scrollbars=yes,status=yes');
}

var HOST = 'sax.pomona.edu';

// Copyright (c) 1996-1997 Athenia Associates.
// http://www.webreference.com/js/
// License is granted if and only if this entire
// copyright notice is included. By Tomer Shiran.

function setCookie (name, value, expires, path, domain, secure) {
    var curCookie = name + "=" + escape(value) + ((expires) ? "; expires=" + expires.toGMTString() : "") + ((path) ? "; path=" + path : "") + ((domain) ? "; domain=" + domain : "") + ((secure) ? "; secure" : "");
    document.cookie = curCookie;
}

function getCookie (name) {
    var prefix = name + '=';
    var c = document.cookie;
    var nullstring = '';
    var cookieStartIndex = c.indexOf(prefix);
    if (cookieStartIndex == -1)
        return nullstring;
    var cookieEndIndex = c.indexOf(";", cookieStartIndex + prefix.length);
    if (cookieEndIndex == -1)
        cookieEndIndex = c.length;
    return unescape(c.substring(cookieStartIndex + prefix.length, cookieEndIndex));
}

function deleteCookie (name, path, domain) {
    if (getCookie(name))
        document.cookie = name + "=" + ((path) ? "; path=" + path : "") + ((domain) ? "; domain=" + domain : "") + "; expires=Thu, 01-Jan-70 00:00:01 GMT";
}

function fixDate (date) {
    var base = new Date(0);
    var skew = base.getTime();
    if (skew > 0)
        date.setTime(date.getTime() - skew);
}

function rememberMe (f) {
    var now = new Date();
    fixDate(now);
    now.setTime(now.getTime() + 365 * 24 * 60 * 60 * 1000);
    setCookie('mtcmtauth', f.author.value, now, '', HOST, '');
    setCookie('mtcmtmail', f.email.value, now, '', HOST, '');
    setCookie('mtcmthome', f.url.value, now, '', HOST, '');
}

function forgetMe (f) {
    deleteCookie('mtcmtmail', '', HOST);
    deleteCookie('mtcmthome', '', HOST);
    deleteCookie('mtcmtauth', '', HOST);
    f.email.value = '';
    f.author.value = '';
    f.url.value = '';
}

//-->
</script>





</head>

<body>

<div id="banner">
<h1><a href="http://machines.pomona.edu/170J-2003/" accesskey="1">The Literary Machine</a></h1>
<span class="description">Writing in the Human/Computer Interface</span>
</div>

<div id="container">

<div class="blog">

<div id="menu">
<a href="http://machines.pomona.edu/170J-2003/archives/2003/09/17/turingwiener.html">&laquo; Turing/Wiener</a> |

<a href="http://machines.pomona.edu/170J-2003/">Main</a>
| <a href="http://machines.pomona.edu/170J-2003/archives/2003/09/22/remedios_varo.html">Remedios Varo &raquo;</a>

</div>

</div>


<div class="blog">

<h2 class="date">September 18, 2003</h2>

<div class="blogbody">

<h3 class="title">The Argument from consciousness and the machine/human divide</h3>

<p>Many of the problems raised by Turing and Wiener have also been raised in the philosophical specialization known as "philosophy of mind." A philosophical model of mind/brain interaction that treats the mind as a kind of computer is called "machine functionalism." I will try to offer what minimal background I know about this model and then suggest how this line of thinking might reveal a possible gap between human and machine thinking.</p>

<p>In 1967, Hilary Putnam published a paper entitled "Psychological Predicates." This paper changed the field of "philosophy of mind" (which examines the interaction between the physical brain and the non-substantial mind) significantly. Primarily, it contributed to the demise of physicalism (also known as reductionism) which posits the mind-brain identity theory (i.e., the idea that the alleged mind <i>is</i> the same as the physical brain, or that the former can be reduced to the latter). In place of this dominant yet philosophically problematic theory, Putnam introduced "functionalism." Jaegwon Kim describes (machine) functionalism as the position that "we can think of the mind as a Turing machine (or a probabilistic automaton)" (<u>Philosophy of Mind</u>). Furthermore, "for something to have mentality - that is, to have a psychology - is for it to be a physically realized Turing machine of appropriate complexity." There is much more to be said about functionalism, but that will suffice as background. (By the way this position has become very influential and, I think, the preeminent model for the mind/ consciousness among philosophers of mind).</p>

<p>Anyway, one of the questions raised by functionalists (and one that is relevant to our purposes in class) is whether human mentality can be equated with machine mentality. In other words, is there a difference between human and computer mentality if, given an identical input, a (complex) computer produces the same output as a human? In terms of the imitation game, is mentality and thought determined merely by a participant's ability to give a humanlike answer to any question?</p>

<p>This question can be confronted in a number of ways (we attempted a few in class). One intriguing response to Turing came from John Searle in an article entitled "Minds, Brains, and Programs" (1980). Searle presented a thought experiment called the "Chinese Room" argument. This argument suggests that human mentality is substantively different from a machine program's mode of "thinking." Instead of putting you all through an awkward summary, I will quote Kim's explanation:</p>

<p>"Imagine someone (say, Searle himself) who understands no Chinese who is confined in a room ('the Chinese room') with a set of rules for systematically transforming strings of symbols to yield further symbol strings. These symbol strings are in fact Chinese expressions, and the transformation rules are purely <i>formal</i> in the sense that their application depends solely on the shapes of the symbols involved, not their meanings. Searle becomes very adept at manipulating Chinese expressions in accordance with the rules given to him (we may suppose that Searle has memorized the whole rule book) so that every time a string of Chinese characters is sent in, Searle quickly goes to work and promptly sends out an appropriate string of Chinese characters. From the perspective of someone outside the room, the input-output relationships are exactly the same as they would be if someone with a genuine understanding of Chinese, instead of Searle, were locked inside the room. And yet Searle does not understand any Chinese, and there is no understanding of Chinese going on anywhere inside the Chinese room."</p>

<p>So, inside the room, there is only a manipulation of expressions (based on their shapes). There is no thorough understanding of (and experience of) the semantics. Searle goes on to argue that the work done by a computer is analagous to what goes on in the Chinese room. Meanings of words are "computationally irrelevant." His ultimate problem with the Turing test is that it does not really account for semantics. Beliefs and desires (human psychological states), on the other hand, necessitate meaning.</p>

<p>I am not sure that I accept Searle's argument, but it is an interesting approach to forming a distinction between machine processes and human thoughts. Do you all think that thinking and consciousness can ever be achieved by machines? Are these terms loaded with connotations of 'what it means to be human' and thus unfair to apply to machines? Despite the complexity of a given machine, is this a problem of type rather than degree? In other words, is consciousness or experience a uniquely human attribute? Or, on the other hand, are  humans (in a sense) just extremely complex machines? Interestingly enough, philosophers have had a greater problem with defining "human consciousness" (or distinguishing it from machine "consciousness") than just about anything else.</p>

<p>I would be interested to see if you all have any ideas about negotiating the human/machine divide or thoughts about why this is such an important question in the first place. Is our 'humanity' at stake in  understanding the mind in terms of computing machines? What are the implications of this discussion for writing, creativity, and the idea of (inter)textual "networks"?</p>

<p>- Patrick Jagoda</p>

<a name="more"></a>


<span class="posted">Posted by pjagoda at September 18, 2003 12:42 AM

<br /></span>

</div>


<div class="comments-head"><a name="comments"></a>Comments</div>




</div>
</div>
</body>
</html>